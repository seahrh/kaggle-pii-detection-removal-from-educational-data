{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7482808b-c292-4843-9dae-951ff5560b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModelForTokenClassification\n",
    "import scml\n",
    "from scml import pandasx as pdx\n",
    "from mylib.ner import NerDataset, evaluation, CustomDebertaV2ForTokenClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5a4aaa0-9ce9-4f95-b1c2-2585ae4e4e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int16, min=-32768, max=32767\n",
      "device=0, NVIDIA GeForce RTX 4070 Ti SUPER\n",
      "Mem Allocated: 0.0 GB\n",
      "Mem Cached:    0.0 GB\n",
      "device=1, NVIDIA GeForce RTX 4070 Ti SUPER\n",
      "Mem Allocated: 0.0 GB\n",
      "Mem Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "tim = scml.Timer()\n",
    "tim.start()\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "percentiles=[.01, .05, .1, .2, .3, .4, .5, .6, .7, .8, .9, .95, .99]\n",
    "pd.set_option(\"max_info_columns\", 9999)\n",
    "pd.set_option(\"display.max_columns\", 9999)\n",
    "pd.set_option(\"display.max_rows\", 9999)\n",
    "pd.set_option('max_colwidth', 9999)\n",
    "tqdm.pandas()\n",
    "scml.seed_everything()\n",
    "info = np.iinfo(np.int16)\n",
    "print(f\"int16, min={info.min}, max={info.max}\")\n",
    "device = torch.device(\"cpu\")\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    batch_size = 128\n",
    "    print(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:1\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"device={i}, {torch.cuda.get_device_name(i)}\")\n",
    "        print('Mem Allocated:', round(torch.cuda.memory_allocated(i)/1024**3,1), 'GB')\n",
    "        print('Mem Cached:   ', round(torch.cuda.memory_reserved(i)/1024**3,1), 'GB')\n",
    "else:\n",
    "    print(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d76be417-30e7-48e2-ae52-5ccd7cd8c0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = Path(\"models/ner/deberta_v3_large/20240423_131925\")\n",
    "validation_data_file = Path(\"input/val_v020.json\")\n",
    "model_max_length = 512\n",
    "window_length = 512\n",
    "window_stride = 256\n",
    "batch_size = 32\n",
    "model_class = \"CustomDebertaV2ForTokenClassification\"\n",
    "#model_class = \"auto\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d307f62-cc21-49c2-b14e-91681ba85928",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pankun/.local/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:550: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(ds)=8,105\n",
      "ds[0]={'input_ids': tensor([    1,  7181,   877,  1393,   288,  4882,   804,  3805, 42621,   366,\n",
      "         1749, 20379,   366,  6292, 12461,  4649,  4150,   288,  4882,   804,\n",
      "         3805, 42621,   267,   262, 19789,   263, 13717,   648,   265,  1749,\n",
      "        20379,   366,  1993,   366,   269,   299,   517,   272,   273, 18770,\n",
      "          469,   406,   323, 38993, 17159, 11351, 25673,   263, 19392,  8402,\n",
      "          366,   291,   990,   826,   266,   988,  4404,   265,  2293,   366,\n",
      "         2352,   366,   263,  4904,   272,   273,   286,  3069,   264,  2685,\n",
      "          323,   279,  1250,   265,   312,  4513,   269,   311,   265,   359,\n",
      "          370,  1318,  5228,   323, 63356,   557,   292,   262, 20953,   263,\n",
      "        25747,   265,   707,   432,   366,  1749, 20379,   888,   266, 20574,\n",
      "         1192,   399,   273,   295, 20170,   263, 32283,   323,   279, 13457,\n",
      "         2163,   265,  1417,   341,  4109, 63726,   366,  2423, 67819,   267,\n",
      "          262,  2450,   366,   263,   262,  5773,  2155,   265,  3167,  8746,\n",
      "          341,   676,   299, 21640,   272,   269,   462, 17374,   263,  6141,\n",
      "          323,  4682,   366,   312,  3463,   288,  3805, 42621,   826,   266,\n",
      "          986,  1100,   265,   648,   323, 42822,   281,  2166,   263,   489,\n",
      "         1041,   264, 11824,   266,  1789,   721,   323,   345,   611,  5197,\n",
      "          270,  3463,   976,   366, 20092,   266,  2816,   265, 32252,   263,\n",
      "         9736,   323,   606,  4117,   286, 17935,   312,   432,   267,  1029,\n",
      "          273,   387,   518,   286,  9051,   323,   573,  1237,   470,   267,\n",
      "          262,   447,   366,   901,   366,  3897,   659,  1579,  1749, 20379,\n",
      "          341,   278,   269,   262,  1447, 28888, 19944,   267,  9314,   366,\n",
      "         1700,   323,   329,  1008,  2537,   269,   266, 15946,   264,   262,\n",
      "         2257,   263,  4603,   265,   316,  3568,   323,   279,  6231,  2250,\n",
      "          263, 13115,  3158,   265,   359, 12920, 20944,   281,  1610, 11534,\n",
      "          323, 19410,   880,   262, 12961,   265,  2082,  2260,   366,   448,\n",
      "          275,   308,   988,  5729,   263,  8592,   366,   269,   299, 12305,\n",
      "          517,   323,   279,  1447, 28888, 19944,   269,   327,   266,  3569,\n",
      "         8605,   272,  3557,   847,  6342, 13119,   366,  1306,   645,   263,\n",
      "         6412,   270,  6880,  6980,   323,  2952, 11076,   269,  1830,   298,\n",
      "          364,   270,   262,  1192,   304,   327,   270,   723,  5409,   323,\n",
      "        21091,   291,   470,   303, 42363,   267,   351,   266,  1539,  6908,\n",
      "          270,   262,  1008,   447,   263,   312,   985,   267,  5582,   278,\n",
      "          323,   344,  4533,   366,   821,   288,  4882,   804,  3805, 42621,\n",
      "          366,  1749, 20379,   366,  6292, 12461,  4649,   366,   826,   351,\n",
      "         2293,   366,   648,   366,   263,  2352,   323,  4134,   366,   312,\n",
      "         1237,   470,   267,   262,   447,   341,   262,  1447, 28888, 19944,\n",
      "          341,   269,   266,  6966,   265,   262, 10120,   316,  3568,  3073,\n",
      "          263,   262,  2558,   265, 12935,   349,   270,   723,  5409,   323,\n",
      "            2,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'labels': tensor([-100,    0,    0,    0,    0,   13, -100,   14,   14,   14,   14, -100,\n",
      "          14,   14,   14, -100,    0,    0,   13, -100,   14,   14,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0, -100,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "        -100,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,   13,   14,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0, -100,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          13, -100,   14,   14,   14,   14, -100,   14,   14,   14, -100,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100])}\n"
     ]
    }
   ],
   "source": [
    "ds = NerDataset.from_json(\n",
    "    filepath=str(validation_data_file),\n",
    "    tokenizer_directory=model_dir,\n",
    "    model_max_length=model_max_length,\n",
    "    window_length=window_length,\n",
    "    window_stride=window_stride,\n",
    ")\n",
    "print(f\"len(ds)={len(ds):,}\\nds[0]={ds[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75e2f77c-cc43-4255-b6eb-25695f073741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomDebertaV2ForTokenClassification(\n",
      "  (deberta): DebertaV2Model(\n",
      "    (embeddings): DebertaV2Embeddings(\n",
      "      (word_embeddings): Embedding(128100, 1024, padding_idx=0)\n",
      "      (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
      "      (dropout): StableDropout()\n",
      "    )\n",
      "    (encoder): DebertaV2Encoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-23): 24 x DebertaV2Layer(\n",
      "          (attention): DebertaV2Attention(\n",
      "            (self): DisentangledSelfAttention(\n",
      "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (pos_dropout): StableDropout()\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "            (output): DebertaV2SelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): DebertaV2Intermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): DebertaV2Output(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (rel_embeddings): Embedding(512, 1024)\n",
      "      (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (classifier): MultiSampleDropout(\n",
      "    (dropouts): ModuleList(\n",
      "      (0-7): 8 x Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (classifier): Linear(in_features=1024, out_features=15, bias=True)\n",
      "  )\n",
      ")\n",
      "CPU times: user 4.18 s, sys: 4.46 s, total: 8.64 s\n",
      "Wall time: 12.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if model_class==\"CustomDebertaV2ForTokenClassification\":\n",
    "    model = CustomDebertaV2ForTokenClassification.from_pretrained(model_dir)\n",
    "else:\n",
    "    model = AutoModelForTokenClassification.from_pretrained(model_dir)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db8ca36c-874d-49f8-99ac-7ed0e5b16568",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predict ner: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 254/254 [04:45<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 35s, sys: 20.8 s, total: 4min 56s\n",
      "Wall time: 4min 56s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pankun/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "/home/pankun/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/pankun/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "res = evaluation(\n",
    "    ds=ds,\n",
    "    model=model,\n",
    "    batch_size=batch_size,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d055977-5d9a-4ab5-91fa-373497a30342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"micro_f5\": 0.7952193707605854,\n",
      "  \"recall\": 0.7893735765948394,\n",
      "  \"precision\": 0.9758972772277228,\n",
      "  \"labels\": {\n",
      "    \"I-URL_PERSONAL\": {\n",
      "      \"micro_f5\": 0.0,\n",
      "      \"recall\": 0.0,\n",
      "      \"precision\": 0.0\n",
      "    },\n",
      "    \"I-ID_NUM\": {\n",
      "      \"micro_f5\": 0.0,\n",
      "      \"recall\": 0.0,\n",
      "      \"precision\": 0.0\n",
      "    },\n",
      "    \"I-EMAIL\": {\n",
      "      \"micro_f5\": 0.0,\n",
      "      \"recall\": 0.0,\n",
      "      \"precision\": 0.0\n",
      "    },\n",
      "    \"I-USERNAME\": {\n",
      "      \"micro_f5\": 0.0,\n",
      "      \"recall\": 0.0,\n",
      "      \"precision\": 0.0\n",
      "    },\n",
      "    \"B-URL_PERSONAL\": {\n",
      "      \"micro_f5\": 0.46452476572958495,\n",
      "      \"recall\": 0.45478374836173,\n",
      "      \"precision\": 1.0\n",
      "    },\n",
      "    \"B-NAME_STUDENT\": {\n",
      "      \"micro_f5\": 0.5121968267281751,\n",
      "      \"recall\": 0.502813229038013,\n",
      "      \"precision\": 0.960167714884696\n",
      "    },\n",
      "    \"I-NAME_STUDENT\": {\n",
      "      \"micro_f5\": 0.766745998234233,\n",
      "      \"recall\": 0.7600791491466733,\n",
      "      \"precision\": 0.9821029082774049\n",
      "    },\n",
      "    \"B-STREET_ADDRESS\": {\n",
      "      \"micro_f5\": 0.8062787136294026,\n",
      "      \"recall\": 0.8007604562737642,\n",
      "      \"precision\": 0.9740980573543015\n",
      "    },\n",
      "    \"I-STREET_ADDRESS\": {\n",
      "      \"micro_f5\": 0.869165071101263,\n",
      "      \"recall\": 0.8649596437517395,\n",
      "      \"precision\": 0.98943011779688\n",
      "    },\n",
      "    \"B-PHONE_NUM\": {\n",
      "      \"micro_f5\": 0.883739920383791,\n",
      "      \"recall\": 0.8797886393659181,\n",
      "      \"precision\": 0.9955156950672646\n",
      "    },\n",
      "    \"B-USERNAME\": {\n",
      "      \"micro_f5\": 0.9349678925861061,\n",
      "      \"recall\": 0.9390243902439024,\n",
      "      \"precision\": 0.8438356164383561\n",
      "    },\n",
      "    \"B-ID_NUM\": {\n",
      "      \"micro_f5\": 0.9595975113295953,\n",
      "      \"recall\": 0.9581256231306082,\n",
      "      \"precision\": 0.9979231568016614\n",
      "    },\n",
      "    \"B-EMAIL\": {\n",
      "      \"micro_f5\": 0.9897376887490315,\n",
      "      \"recall\": 0.9920440636474909,\n",
      "      \"precision\": 0.9353721869590306\n",
      "    },\n",
      "    \"I-PHONE_NUM\": {\n",
      "      \"micro_f5\": 0.9937274359129507,\n",
      "      \"recall\": 0.9952731092436975,\n",
      "      \"precision\": 0.9565875820292782\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(res, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c363b3f8-51b7-42f8-a917-b654fe2a3d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken 0:05:09.995752\n"
     ]
    }
   ],
   "source": [
    "tim.stop()\n",
    "print(f\"Total time taken {str(tim.elapsed)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
