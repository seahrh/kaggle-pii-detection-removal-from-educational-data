{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7482808b-c292-4843-9dae-951ff5560b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int16, min=-32768, max=32767\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModelForTokenClassification\n",
    "import scml\n",
    "from scml import pandasx as pdx\n",
    "from mylib.ner import NerDataset, evaluation\n",
    "tim = scml.Timer()\n",
    "tim.start()\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "percentiles=[.01, .05, .1, .2, .3, .4, .5, .6, .7, .8, .9, .95, .99]\n",
    "pd.set_option(\"max_info_columns\", 9999)\n",
    "pd.set_option(\"display.max_columns\", 9999)\n",
    "pd.set_option(\"display.max_rows\", 9999)\n",
    "pd.set_option('max_colwidth', 9999)\n",
    "tqdm.pandas()\n",
    "scml.seed_everything()\n",
    "info = np.iinfo(np.int16)\n",
    "print(f\"int16, min={info.min}, max={info.max}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d76be417-30e7-48e2-ae52-5ccd7cd8c0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = Path(\"models/ner/deberta_v3_large/20240324_153756\")\n",
    "validation_data_file = Path(\"input/val_240102.json\")\n",
    "model_max_length = 768\n",
    "window_length = 768\n",
    "window_stride = 256\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44916b07-d32e-4fb0-a869-76bddd1f86bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device=0, NVIDIA GeForce RTX 4070 Ti SUPER\n",
      "Mem Allocated: 0.0 GB\n",
      "Mem Cached:    0.0 GB\n",
      "device=1, NVIDIA GeForce RTX 4070 Ti SUPER\n",
      "Mem Allocated: 0.0 GB\n",
      "Mem Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    batch_size = 128\n",
    "    print(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:1\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"device={i}, {torch.cuda.get_device_name(i)}\")\n",
    "        print('Mem Allocated:', round(torch.cuda.memory_allocated(i)/1024**3,1), 'GB')\n",
    "        print('Mem Cached:   ', round(torch.cuda.memory_reserved(i)/1024**3,1), 'GB')\n",
    "else:\n",
    "    print(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d307f62-cc21-49c2-b14e-91681ba85928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(ds)=1,303\n",
      "ds[0]={'input_ids': tensor([    1,  2169, 12103,   270,  8432, 63632,   608,  3365, 26097, 50209,\n",
      "          358,   689,  1374,   366, 16789,  6738,   573,  1719,   264,  3634,\n",
      "          269,   262,   735,   265,   266,   483,   272,   269,   497,  4172,\n",
      "         1909,   264,   676,   263,  1044,   359,   451,  2746,  1696,   366,\n",
      "          263,   295,   298,  8563,   275,   262,  1479,  1935,   272,   306,\n",
      "          286,   330,   267,   262,   437,   375,   740,   323,   279,   483,\n",
      "          269,   267,   266, 14920,   366,   283,   278,   303,   375,  1068,\n",
      "         2848,  2600,   279,   362,  7031,   826,   262,   906,   265,  1909,\n",
      "         1241,   270,   262,  2820,   265,   262,  1696,   366,   267,  1067,\n",
      "          313,  5387,   264, 16902,   267,   262,   568,   263,   365,   991,\n",
      "         1028,   267,   262,  1061,   714,   515,   313,  5470,   272,   262,\n",
      "          781,   313,   303,   303,  1569,   397,   793,   267,  1404,   388,\n",
      "          263,   264,   286,   262,  4351,   265,   960,  4639,   267,   262,\n",
      "          483,   366,   262,   567,  7031,   826,   262,  1909,  1241,   270,\n",
      "          262,  2820,   265,   262,  1696,   267,  2395,   270,   333,   298,\n",
      "          365, 10035,   264,   262,  1061,   714,   366,   515,   291,   269,\n",
      "          262,   311,   272,   269,  7420,   262, 26120,  1074,   265,   262,\n",
      "          483,   366,   270,   262,  1170,   278,   269,   364,   921,   264,\n",
      "         1087,   277,   262,   483,   382,   268,  1228,   714,   263,   283,\n",
      "          306,  5462,   262,  1578,   306,   295,   282,  3079,   264,   262,\n",
      "         3513,   265,   633,   263,  2820,   270,   266,   602,  4639,  6543,\n",
      "          546,   262,   483,   323,   463,   266,  2140,   265,   262,   483,\n",
      "          366,   273,   389,   264,   365,   262,   410,  1129,   270,   262,\n",
      "          764,  1979,   311,   323, 14700,   273,  1216,   264,  1003,   262,\n",
      "        15895,  1637,   366, 15895,  1279,   351,   264,   796,   263,  6647,\n",
      "          262,  2758,   366,   264,   282,   526,   264,  4578,   262,   634,\n",
      "          263,   308,   628,  1527,   323,   329,  1637,   269,  1772,   270,\n",
      "          351,   264,   286,   266, 14025,  2345,   265,   262,   763,   565,\n",
      "          265,   262,   483,   263,   339,   278,  3453,  1956,  2600,   390,\n",
      "          291,  1637,   273,   295, 53239,   262, 11440,   265,   262,   375,\n",
      "         2848,   366,   405,   283,  2235,   263, 21150,  2600,   263,   636,\n",
      "          277,   291,   273,   295,   365,   262,   410,  1129,   323,  5736,\n",
      "          344,   262,  1055,   265,   312,  2915,  1637,   264,   262,  1719,\n",
      "          272,   273,   286,   487,  1113,   366,   262,  1637,   303,   331,\n",
      "          265,   266,   379,  1182,  4729,   366,   515,   335,  4422,   278,\n",
      "          264,   312,  1719,   379,   397,   793,   332,  3238,   366,   515,\n",
      "          275,   291,   273,   387,   286,   299,  1423,   264,   262,  2520,\n",
      "          265,   262,   375,  2848,   323,   279,   362,   576,   273,   464,\n",
      "          275,   312, 15895,  1637,   284,   264,  3360,   266,   797,   264,\n",
      "          887,   328,   886,   262, 11034,   714,   265,   262,   483,   366,\n",
      "          362,   273,   330,   264,   796,   579,   262,  1935,   330,   330,\n",
      "          405,   266,   986,  1074,   267,   262,   437,   375,   740,   366,\n",
      "          293,  4422,   262,  1637,   273,   387,   433,   262,  2995,   264,\n",
      "          291,   900,  2600,   273,   387,   398,   272,   887,   858,   291,\n",
      "          714,   283,   278,   284,   366,   497,   356, 10109,   401,   262,\n",
      "          714,  1103, 10120,   323,   559,   291,   797,   265,   262,  1187,\n",
      "         1408,   267,   262,   714,   366,   273,   284,   526,   264,  6647,\n",
      "          263,  1111,   322,   277,   262,  6719,   273,   330,   277,   262,\n",
      "         1108,   292,   262,   375,  2848,   323,   273,  5988,   272,   273,\n",
      "          858,   262,   604,   328,   284,  1408,   267,   262,   362,  2552,\n",
      "          264,  1709,   262,   714,   272,   284,   591,   426,  1228,   323,\n",
      "         2597,   284,   262,   567,  7031,   366,   515,   313,   284,  1408,\n",
      "          267,   362,   265,   305,   264,   527,   262,   884,   265,  1117,\n",
      "          272,   316,   887,  9221,   366,   263,   393,  2551,   314,  3609,\n",
      "          278,   366,   304,   267,   536,   263, 12736,  1884,   323,   273,\n",
      "        16952,   262,   362,  7031,   366,   283,   313,   464,   298,   957,\n",
      "          262,  1546,   272,   262,   483,   858,   288,   272,   326,   323,\n",
      "          273,  3164,   272,   291,  7031,   284,  5926,   272,   293,  2198,\n",
      "          262,   714,   264,   262,   384,   313,   708,   366,   262,  1935,\n",
      "          284,   446,   264,   993,   310,  2600,   304,   267,  1901,   339,\n",
      "          262,   483,   858,   284,   264,   282,   526,   264,  1134,   262,\n",
      "         1935,   272,   262,   714,   284,   591,   366,   291,  7031,   849,\n",
      "          264,  3054,   758,   301,   330,   366,   264,   262,   626,   265,\n",
      "          262,  1212,   366,   304,   313,   464,   298,   428,   270,   266,\n",
      "         1170,   272,   378, 10035,   403,   286,   266,   759,  1239,   267,\n",
      "          571,   479,   333,   298,   424,   283,   371,   283,  1256,   323,\n",
      "         1195,   264,   262,  1055,   265,   262,  1637,   273,   284,   526,\n",
      "          264,  2313,   262,   896,   911,   265,   262,   483,   382,   268,\n",
      "          634,   263,   361,   448,  7031,   366,   970,   264,   308,  6719,\n",
      "          366,   387,   408,   351,   366,   636,   277,   291,   273,   412,\n",
      "          262,   410,  1129,   323,   273,  3537,   264,   374,   275,   262,\n",
      "          567,  7031,   366,   301,     2,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'labels': tensor([-100,    0,    0,    0,    0,    1, -100,    2, -100,    0, -100,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0, -100,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0, -100,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pankun/.local/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:515: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ds = NerDataset.from_json(\n",
    "    filepath=str(validation_data_file),\n",
    "    tokenizer_directory=model_dir,\n",
    "    model_max_length=model_max_length,\n",
    "    window_length=window_length,\n",
    "    window_stride=window_stride,\n",
    ")\n",
    "print(f\"len(ds)={len(ds):,}\\nds[0]={ds[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75e2f77c-cc43-4255-b6eb-25695f073741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DebertaV2ForTokenClassification(\n",
      "  (deberta): DebertaV2Model(\n",
      "    (embeddings): DebertaV2Embeddings(\n",
      "      (word_embeddings): Embedding(128100, 1024, padding_idx=0)\n",
      "      (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
      "      (dropout): StableDropout()\n",
      "    )\n",
      "    (encoder): DebertaV2Encoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-23): 24 x DebertaV2Layer(\n",
      "          (attention): DebertaV2Attention(\n",
      "            (self): DisentangledSelfAttention(\n",
      "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (pos_dropout): StableDropout()\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "            (output): DebertaV2SelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): DebertaV2Intermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): DebertaV2Output(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (rel_embeddings): Embedding(512, 1024)\n",
      "      (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): Linear(in_features=1024, out_features=15, bias=True)\n",
      ")\n",
      "CPU times: user 4.72 s, sys: 3.69 s, total: 8.41 s\n",
      "Wall time: 12.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_dir)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db8ca36c-874d-49f8-99ac-7ed0e5b16568",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predict ner: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 41/41 [01:24<00:00,  2.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 23s, sys: 5.75 s, total: 1min 29s\n",
      "Wall time: 1min 29s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pankun/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "/home/pankun/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/pankun/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "res = evaluation(\n",
    "    ds=ds,\n",
    "    model=model,\n",
    "    batch_size=batch_size,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d055977-5d9a-4ab5-91fa-373497a30342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"micro_f5\": 0.9930982759082507,\n",
      "  \"recall\": 0.992920970175235,\n",
      "  \"precision\": 0.9975515914655474,\n",
      "  \"labels\": {\n",
      "    \"I-URL_PERSONAL\": {\n",
      "      \"micro_f5\": 0.0,\n",
      "      \"recall\": 0.0,\n",
      "      \"precision\": 0.0\n",
      "    },\n",
      "    \"I-EMAIL\": {\n",
      "      \"micro_f5\": 0.0,\n",
      "      \"recall\": 0.0,\n",
      "      \"precision\": 0.0\n",
      "    },\n",
      "    \"I-USERNAME\": {\n",
      "      \"micro_f5\": 0.0,\n",
      "      \"recall\": 0.0,\n",
      "      \"precision\": 0.0\n",
      "    },\n",
      "    \"B-STREET_ADDRESS\": {\n",
      "      \"micro_f5\": 0.9654677549556012,\n",
      "      \"recall\": 0.965034965034965,\n",
      "      \"precision\": 0.9764150943396226\n",
      "    },\n",
      "    \"B-NAME_STUDENT\": {\n",
      "      \"micro_f5\": 0.9856202178506225,\n",
      "      \"recall\": 0.9850746268656716,\n",
      "      \"precision\": 0.9994591671173607\n",
      "    },\n",
      "    \"I-ID_NUM\": {\n",
      "      \"micro_f5\": 0.990234375,\n",
      "      \"recall\": 0.9898477157360406,\n",
      "      \"precision\": 1.0\n",
      "    },\n",
      "    \"B-ID_NUM\": {\n",
      "      \"micro_f5\": 0.9910104279036318,\n",
      "      \"recall\": 0.9906542056074766,\n",
      "      \"precision\": 1.0\n",
      "    },\n",
      "    \"I-NAME_STUDENT\": {\n",
      "      \"micro_f5\": 0.9911846582121868,\n",
      "      \"recall\": 0.9909547738693467,\n",
      "      \"precision\": 0.9969666329625885\n",
      "    },\n",
      "    \"I-STREET_ADDRESS\": {\n",
      "      \"micro_f5\": 0.9985190297488102,\n",
      "      \"recall\": 0.9985046728971962,\n",
      "      \"precision\": 0.9988780852655198\n",
      "    },\n",
      "    \"B-PHONE_NUM\": {\n",
      "      \"micro_f5\": 0.9995790655254665,\n",
      "      \"recall\": 1.0,\n",
      "      \"precision\": 0.9891696750902527\n",
      "    },\n",
      "    \"I-PHONE_NUM\": {\n",
      "      \"micro_f5\": 0.9999572667834709,\n",
      "      \"recall\": 1.0,\n",
      "      \"precision\": 0.9988901220865705\n",
      "    },\n",
      "    \"B-URL_PERSONAL\": {\n",
      "      \"micro_f5\": 1.0,\n",
      "      \"recall\": 1.0,\n",
      "      \"precision\": 1.0\n",
      "    },\n",
      "    \"B-EMAIL\": {\n",
      "      \"micro_f5\": 1.0,\n",
      "      \"recall\": 1.0,\n",
      "      \"precision\": 1.0\n",
      "    },\n",
      "    \"B-USERNAME\": {\n",
      "      \"micro_f5\": 1.0,\n",
      "      \"recall\": 1.0,\n",
      "      \"precision\": 1.0\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(res, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c363b3f8-51b7-42f8-a917-b654fe2a3d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken 0:01:42.792263\n"
     ]
    }
   ],
   "source": [
    "tim.stop()\n",
    "print(f\"Total time taken {str(tim.elapsed)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
