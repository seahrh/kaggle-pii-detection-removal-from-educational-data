{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b7fc3e8",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-04-23T22:40:47.726953Z",
     "iopub.status.busy": "2024-04-23T22:40:47.726123Z",
     "iopub.status.idle": "2024-04-23T22:40:54.178055Z",
     "shell.execute_reply": "2024-04-23T22:40:54.176747Z"
    },
    "papermill": {
     "duration": 6.461061,
     "end_time": "2024-04-23T22:40:54.181447",
     "exception": false,
     "start_time": "2024-04-23T22:40:47.720386",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import shutil\n",
    "import json\n",
    "import math\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict, List, Tuple, NamedTuple, Callable, Iterable, Set, Optional, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83f006f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T22:40:54.192484Z",
     "iopub.status.busy": "2024-04-23T22:40:54.191943Z",
     "iopub.status.idle": "2024-04-23T22:40:54.204094Z",
     "shell.execute_reply": "2024-04-23T22:40:54.203041Z"
    },
    "papermill": {
     "duration": 0.019854,
     "end_time": "2024-04-23T22:40:54.206283",
     "exception": false,
     "start_time": "2024-04-23T22:40:54.186429",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conf(debug=False, input_dir=PosixPath('/kaggle/input'), comp_dir=PosixPath('/kaggle/input/pii-detection-removal-from-educational-data'), temp_dir=PosixPath('/kaggle/temp'), working_dir=PosixPath('/kaggle/working'), resource_dir=PosixPath('/kaggle/input/libtlalpii/tlal-pii-0.1'), data_dir=PosixPath('/kaggle/input/libtlalpii/tlal-pii-0.1/input'), models=[ModelConf(name='deberta_v3_base', directory=PosixPath('/kaggle/input/libtlalpii/tlal-pii-0.1/models/ner/deberta_v3_base/20240420_185849'), model_max_length=512, batch_size=32, weight=0.5), ModelConf(name='deberta_v3_large', directory=PosixPath('/kaggle/input/libtlalpii/tlal-pii-0.1/models/ner/deberta_v3_large/20240421_072931'), model_max_length=512, batch_size=32, weight=0.5)], window_length=512, window_stride=256, outside_label_threshold=0.8, duplicate_dt_strategy='first')\n"
     ]
    }
   ],
   "source": [
    "class ModelConf(NamedTuple):\n",
    "    name: str\n",
    "    directory: Path\n",
    "    model_max_length: int=512\n",
    "    batch_size: int=16\n",
    "    weight: float=1\n",
    "        \n",
    "\n",
    "class Conf(NamedTuple):\n",
    "    debug: bool = False  #not os.getenv('KAGGLE_IS_COMPETITION_RERUN', False)\n",
    "    input_dir: Path = Path(\"/kaggle/input\")\n",
    "    comp_dir: Path = input_dir / \"pii-detection-removal-from-educational-data\"\n",
    "    temp_dir: Path = Path('/kaggle/temp')\n",
    "    # write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "    working_dir: Path = Path('/kaggle/working')\n",
    "    resource_dir: Path = input_dir / \"libtlalpii/tlal-pii-0.1\"\n",
    "    data_dir: Path = resource_dir / \"input\"\n",
    "    models: List[ModelConf] = [\n",
    "        ModelConf(\n",
    "            name=\"deberta_v3_base\",\n",
    "            directory=Path(resource_dir) / \"models/ner/deberta_v3_base/20240420_185849\",\n",
    "            model_max_length=512,\n",
    "            batch_size=32,\n",
    "            weight=0.5,\n",
    "        ),\n",
    "        ModelConf(\n",
    "            name=\"deberta_v3_large\",\n",
    "            directory=Path(resource_dir) / \"models/ner/deberta_v3_large/20240421_072931\",\n",
    "            model_max_length=512,\n",
    "            batch_size=32,\n",
    "            weight=0.5,\n",
    "        ),\n",
    "    ]\n",
    "    window_length: int = 512\n",
    "    window_stride: int = 256\n",
    "    outside_label_threshold: float = 0.80\n",
    "    duplicate_dt_strategy: str = \"first\"  # first, mean, min_outside_proba \n",
    "\n",
    "conf = Conf()\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d72de28e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T22:40:54.215986Z",
     "iopub.status.busy": "2024-04-23T22:40:54.215642Z",
     "iopub.status.idle": "2024-04-23T22:40:54.298936Z",
     "shell.execute_reply": "2024-04-23T22:40:54.297808Z"
    },
    "papermill": {
     "duration": 0.090644,
     "end_time": "2024-04-23T22:40:54.300906",
     "exception": false,
     "start_time": "2024-04-23T22:40:54.210262",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device=0, Tesla P100-PCIE-16GB\n",
      "Mem Allocated: 0.0 GB\n",
      "Mem Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"device={i}, {torch.cuda.get_device_name(i)}\")\n",
    "        print('Mem Allocated:', round(torch.cuda.memory_allocated(i)/1024**3,1), 'GB')\n",
    "        print('Mem Cached:   ', round(torch.cuda.memory_reserved(i)/1024**3,1), 'GB')\n",
    "else:\n",
    "    print(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5372d03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T22:40:54.310933Z",
     "iopub.status.busy": "2024-04-23T22:40:54.310233Z",
     "iopub.status.idle": "2024-04-23T22:40:59.450511Z",
     "shell.execute_reply": "2024-04-23T22:40:59.449699Z"
    },
    "papermill": {
     "duration": 5.147532,
     "end_time": "2024-04-23T22:40:59.452738",
     "exception": false,
     "start_time": "2024-04-23T22:40:54.305206",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "percentiles=[.01, .05, .1, .2, .3, .4, .5, .6, .7, .8, .9, .95, .99]\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "pd.set_option(\"max_info_columns\", 9999)\n",
    "pd.set_option(\"display.max_columns\", 9999)\n",
    "pd.set_option(\"display.max_rows\", 9999)\n",
    "pd.set_option('max_colwidth', 9999)\n",
    "tqdm.pandas()\n",
    "sys.path.append(str(conf.input_dir / \"sgcharts-ml/src\"))\n",
    "sys.path.append(str(conf.resource_dir / \"src\"))\n",
    "import scml\n",
    "from scml import nlp as snlp\n",
    "from scml import pandasx as pdx\n",
    "from mylib.ner import predict_ner_proba, NerDataset, blend_predictions\n",
    "from warnings import simplefilter \n",
    "simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "scml.seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a0fd17e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T22:40:59.463280Z",
     "iopub.status.busy": "2024-04-23T22:40:59.462822Z",
     "iopub.status.idle": "2024-04-23T22:40:59.484504Z",
     "shell.execute_reply": "2024-04-23T22:40:59.483477Z"
    },
    "papermill": {
     "duration": 0.029079,
     "end_time": "2024-04-23T22:40:59.486365",
     "exception": false,
     "start_time": "2024-04-23T22:40:59.457286",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(data)=10\n"
     ]
    }
   ],
   "source": [
    "fp = conf.comp_dir / \"test.json\"\n",
    "if conf.debug:\n",
    "    fp = conf.comp_dir / \"train.json\"\n",
    "with open(str(fp)) as f:\n",
    "    data = json.load(f)\n",
    "print(f\"len(data)={len(data)}\")\n",
    "texts: List[List[str]] = []\n",
    "dids: List[str] = []\n",
    "for row in data:\n",
    "    texts.append(row[\"tokens\"])\n",
    "    dids.append(str(row[\"document\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538b64c5",
   "metadata": {
    "papermill": {
     "duration": 0.004033,
     "end_time": "2024-04-23T22:40:59.494734",
     "exception": false,
     "start_time": "2024-04-23T22:40:59.490701",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5520d772",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T22:40:59.504229Z",
     "iopub.status.busy": "2024-04-23T22:40:59.503945Z",
     "iopub.status.idle": "2024-04-23T22:41:25.869907Z",
     "shell.execute_reply": "2024-04-23T22:41:25.868971Z"
    },
    "papermill": {
     "duration": 26.373282,
     "end_time": "2024-04-23T22:41:25.872167",
     "exception": false,
     "start_time": "2024-04-23T22:40:59.498885",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deberta_v3_base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:515: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38, 512, 15) y_proba[0][0]=[0.07480966 0.06523772 0.0831486  0.06141015 0.06134651 0.07266962\n",
      " 0.06743815 0.05385804 0.06865056 0.05009668 0.07634687 0.04750584\n",
      " 0.10992236 0.05568699 0.05187228]\n",
      "deberta_v3_large\n",
      "(38, 512, 15) y_proba[0][0]=[0.0854906  0.18612398 0.02502726 0.05608674 0.05952589 0.1378629\n",
      " 0.02561215 0.04259685 0.04575884 0.06643269 0.04495351 0.08801769\n",
      " 0.03996282 0.01869089 0.07785716]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = NerDataset(\n",
    "    tokenizer=None,\n",
    "    texts=texts,\n",
    "    document_ids=dids,\n",
    "    window_length=conf.window_length,\n",
    "    window_stride=conf.window_stride,\n",
    ")\n",
    "dwm_map=defaultdict(list)\n",
    "for m, mc in enumerate(conf.models):\n",
    "    print(mc.name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        str(mc.directory),\n",
    "        model_max_length=mc.model_max_length,\n",
    "    )\n",
    "    ds.tokenizer = tokenizer\n",
    "    model = AutoModelForTokenClassification.from_pretrained(str(mc.directory))\n",
    "    # (seqs, sequence length in tokens, classes)\n",
    "    y_proba = predict_ner_proba(\n",
    "        ds=ds,\n",
    "        model=model,\n",
    "        batch_size=mc.batch_size,\n",
    "        device=device,\n",
    "    )\n",
    "    print(f\"{y_proba.shape} y_proba[0][0]={y_proba[0][0]}\")\n",
    "    # token-to-word mapping (document, word): (models, classes)\n",
    "    for i in range(len(y_proba)):\n",
    "        d=int(ds.document_ids[i])\n",
    "        for j in range(len(y_proba[i])):\n",
    "            w = ds.word_ids[i][j]\n",
    "            if w is None:\n",
    "                continue\n",
    "            w+=ds.word_ranges[i][0]\n",
    "            # collect all predictions including duplicate doc-word pairs\n",
    "            if conf.duplicate_dt_strategy==\"first\" and len(dwm_map[(d,w,m)])!=0:\n",
    "                continue\n",
    "            dwm_map[(d,w,m)].append(y_proba[i][j])\n",
    "dw_map=defaultdict(list)\n",
    "for k,v in dwm_map.items():\n",
    "    d,w,m = k\n",
    "    if conf.duplicate_dt_strategy==\"min_outside_proba\":\n",
    "        i = np.argmin(v, axis=0)[0]  # `Outside` label at index 0\n",
    "        dw_map[(d,w)].append(v[i].flatten().tolist())\n",
    "    else:\n",
    "        dw_map[(d,w)].append(np.mean(v, axis=0).flatten().tolist()) \n",
    "del dwm_map\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "537d3b59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T22:41:25.883387Z",
     "iopub.status.busy": "2024-04-23T22:41:25.883088Z",
     "iopub.status.idle": "2024-04-23T22:41:26.165009Z",
     "shell.execute_reply": "2024-04-23T22:41:26.164108Z"
    },
    "papermill": {
     "duration": 0.289993,
     "end_time": "2024-04-23T22:41:26.167093",
     "exception": false,
     "start_time": "2024-04-23T22:41:25.877100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del texts, dids, ds, model, tokenizer\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de24a291",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T22:41:26.178381Z",
     "iopub.status.busy": "2024-04-23T22:41:26.178117Z",
     "iopub.status.idle": "2024-04-23T22:41:26.320796Z",
     "shell.execute_reply": "2024-04-23T22:41:26.319825Z"
    },
    "papermill": {
     "duration": 0.150676,
     "end_time": "2024-04-23T22:41:26.322927",
     "exception": false,
     "start_time": "2024-04-23T22:41:26.172251",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 34 entries, 0 to 33\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   document  34 non-null     int64 \n",
      " 1   token     34 non-null     int64 \n",
      " 2   label     34 non-null     object\n",
      " 3   row_id    34 non-null     int64 \n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 1.2+ KB\n"
     ]
    }
   ],
   "source": [
    "sub = blend_predictions(\n",
    "    weights=np.array([[mc.weight for mc in conf.models]], dtype=np.float32),\n",
    "    dw_map=dw_map,\n",
    "    outside_label_threshold=conf.outside_label_threshold,\n",
    ")\n",
    "sub.to_csv(\"submission.csv\", index=False)\n",
    "sub.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e06c5a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T22:41:26.333978Z",
     "iopub.status.busy": "2024-04-23T22:41:26.333693Z",
     "iopub.status.idle": "2024-04-23T22:41:26.345763Z",
     "shell.execute_reply": "2024-04-23T22:41:26.344929Z"
    },
    "papermill": {
     "duration": 0.019776,
     "end_time": "2024-04-23T22:41:26.347692",
     "exception": false,
     "start_time": "2024-04-23T22:41:26.327916",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>token</th>\n",
       "      <th>label</th>\n",
       "      <th>row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>482</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>483</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>738</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>741</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>742</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>464</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   document  token           label  row_id\n",
       "0         7      9  B-NAME_STUDENT       0\n",
       "1         7     10  I-NAME_STUDENT       1\n",
       "2         7    482  B-NAME_STUDENT       2\n",
       "3         7    483  I-NAME_STUDENT       3\n",
       "4         7    738  B-NAME_STUDENT       4\n",
       "5         7    741  B-NAME_STUDENT       5\n",
       "6         7    742  I-NAME_STUDENT       6\n",
       "7        10      0  B-NAME_STUDENT       7\n",
       "8        10      1  I-NAME_STUDENT       8\n",
       "9        10    464  B-NAME_STUDENT       9"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e79d9d5",
   "metadata": {
    "papermill": {
     "duration": 0.004772,
     "end_time": "2024-04-23T22:41:26.357703",
     "exception": false,
     "start_time": "2024-04-23T22:41:26.352931",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a5ef69f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T22:41:26.369002Z",
     "iopub.status.busy": "2024-04-23T22:41:26.368704Z",
     "iopub.status.idle": "2024-04-23T22:41:26.372349Z",
     "shell.execute_reply": "2024-04-23T22:41:26.371472Z"
    },
    "papermill": {
     "duration": 0.011407,
     "end_time": "2024-04-23T22:41:26.374245",
     "exception": false,
     "start_time": "2024-04-23T22:41:26.362838",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!python -V && which python\n",
    "#!pip list"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 7500999,
     "sourceId": 66653,
     "sourceType": "competition"
    },
    {
     "datasetId": 960933,
     "sourceId": 7655112,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4463009,
     "sourceId": 8120396,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30646,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 44.180432,
   "end_time": "2024-04-23T22:41:29.127975",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-23T22:40:44.947543",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
