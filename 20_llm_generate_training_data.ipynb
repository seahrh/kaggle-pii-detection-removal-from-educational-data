{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b4d1d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accelerate=0.29.2, bitsandbytes=0.43.1\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import shutil\n",
    "import json\n",
    "import math\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import bitsandbytes\n",
    "import accelerate\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict, List, Tuple, NamedTuple, Callable, Iterable, Set, Optional, Any\n",
    "import scml\n",
    "from mylib.datageneration import Prompter\n",
    "print(f\"accelerate={accelerate.__version__}, bitsandbytes={bitsandbytes.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75a2772b",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = 30*6\n",
    "model_dir = Path(\"/mnt/c/huggingface/mistralai/Mixtral-8x7B-Instruct-v0.1\")\n",
    "model_max_length = 4096\n",
    "seed = 422"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e197c9ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device=0, NVIDIA GeForce RTX 4070 Ti SUPER\n",
      "Mem Allocated: 0.0 GB\n",
      "Mem Cached:    0.0 GB\n",
      "device=1, NVIDIA GeForce RTX 4070 Ti SUPER\n",
      "Mem Allocated: 0.0 GB\n",
      "Mem Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "tim = scml.Timer()\n",
    "tim.start()\n",
    "percentiles=[.01, .05, .1, .2, .3, .4, .5, .6, .7, .8, .9, .95, .99]\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "pd.set_option(\"max_info_columns\", 9999)\n",
    "pd.set_option(\"display.max_columns\", 9999)\n",
    "pd.set_option(\"display.max_rows\", 9999)\n",
    "pd.set_option('max_colwidth', 9999)\n",
    "tqdm.pandas()\n",
    "scml.seed_everything(seed)\n",
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"device={i}, {torch.cuda.get_device_name(i)}\")\n",
    "        print('Mem Allocated:', round(torch.cuda.memory_allocated(i)/1024**3,1), 'GB')\n",
    "        print('Mem Cached:   ', round(torch.cuda.memory_reserved(i)/1024**3,1), 'GB')\n",
    "else:\n",
    "    print(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd6b1da1-24ed-43b4-87fe-6f7a2202bac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104 student names\n"
     ]
    }
   ],
   "source": [
    "with open(\"input/student_names.json\") as f:\n",
    "    student_names = set(json.load(f))\n",
    "print(f\"{len(student_names):,} student names\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8bf706b-654a-4e51-9a88-61bb16a6584a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11,562 street addresses=['Adis Road (Liv On Sophia)', 'Adis Road (Parc Sophia)', 'Admiralty Drive (Block 353A)', 'Admiralty Drive (Block 353B)', 'Admiralty Drive (Block 353C)', 'Admiralty Drive (Block 354A)', 'Admiralty Drive (Block 354C)', 'Admiralty Drive (Block 354D)', 'Admiralty Drive (Block 356B)', 'Admiralty Drive (Block 356C)']\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11562 entries, 0 to 11561\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   street  11562 non-null  object \n",
      " 1   lat     11562 non-null  float64\n",
      " 2   lng     11562 non-null  float64\n",
      "dtypes: float64(2), object(1)\n",
      "memory usage: 271.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"input/geocode-db.csv\", low_memory=False, names=[\"street\",\"lat\",\"lng\"])\n",
    "street_addresses = [x.title() for x in df[\"street\"]]\n",
    "print(f\"{len(street_addresses):,} street addresses={street_addresses[:10]}\")\n",
    "street_addresses = set(street_addresses)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17d5b87a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaTokenizerFast(name_or_path='/mnt/c/huggingface/mistralai/Mixtral-8x7B-Instruct-v0.1', vocab_size=32000, model_max_length=4096, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '</s>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
      "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n",
      "model_input_names=['input_ids', 'attention_mask']\n",
      "pad_token_id=2\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(str(model_dir), model_max_length=model_max_length)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "print(f\"{repr(tokenizer)}\\nmodel_input_names={tokenizer.model_input_names}\")\n",
    "print(f\"pad_token_id={tokenizer.pad_token_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6e82067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc2e3f6ea9294452b7b6965e80072e88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 9s, sys: 3min 34s, total: 7min 43s\n",
      "Wall time: 14min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    str(model_dir),\n",
    "    device_map = \"auto\",\n",
    "    quantization_config=quantization_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83c69bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MixtralForCausalLM(\n",
      "  (model): MixtralModel(\n",
      "    (embed_tokens): Embedding(32000, 4096)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x MixtralDecoderLayer(\n",
      "        (self_attn): MixtralSdpaAttention(\n",
      "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): MixtralRotaryEmbedding()\n",
      "        )\n",
      "        (block_sparse_moe): MixtralSparseMoeBlock(\n",
      "          (gate): Linear4bit(in_features=4096, out_features=8, bias=False)\n",
      "          (experts): ModuleList(\n",
      "            (0-7): 8 x MixtralBlockSparseTop2MLP(\n",
      "              (w1): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "              (w2): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "              (w3): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "              (act_fn): SiLU()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (input_layernorm): MixtralRMSNorm()\n",
      "        (post_attention_layernorm): MixtralRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): MixtralRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "764bc968-691f-4d51-b107-3935334e099e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] Write a short essay on the following topic:\n",
      "        In Education Policy and Reform, how can the integration of a learning launch tool within the design thinking process enhance the development and testing of ideas, prototypes, and products?\n",
      "        Intersperse the following information in different parts of the essay:\n",
      "        1. Give an example that occurred near Pasir Ris Street 11 (Block 125), at a school frequented by Justin Kaiser\n",
      "        2. Give an example citing someone named JustinKaiser\n",
      "        3. Give an example citing: periscope.tv/officialjustiniamkaiser [/INST]\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "prompter = Prompter(target_size=target_size, student_names=student_names, street_addresses=street_addresses)\n",
    "res = prompter.prompt()\n",
    "print(res.prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784f0d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|████████████████████████████████████████████████████████████████████████████████████████▊                                                       | 111/180 [3:19:09<2:12:45, 115.44s/it]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rows = []\n",
    "for _ in tqdm(range(target_size)):\n",
    "    res = prompter.prompt()\n",
    "    inputs = tokenizer(res.prompt, return_tensors=\"pt\").to(device)\n",
    "    outputs = model.generate(\n",
    "        **inputs, \n",
    "        max_new_tokens=512,\n",
    "        do_sample=True,\n",
    "        temperature=1.0,\n",
    "        top_p=0.95,\n",
    "        top_k=100,\n",
    "        repetition_penalty=1.1,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "    generated_text = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "    generated_text = generated_text.split(\"[/INST]\")[1]\n",
    "    generated_text = generated_text.strip()\n",
    "    rows.append({\n",
    "        \"text\": generated_text,\n",
    "        \"prompt\": res.prompt,\n",
    "        \"street_address\": res.street_address,\n",
    "        \"student_name\": res.student_name,\n",
    "        \"username\": res.username,\n",
    "        \"personal_url\": res.personal_url,\n",
    "        \"model\": model_dir.name,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b64fa3-bc66-4aa0-ac36-7ddba1598aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_records(rows)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efe748b-2f3f-4366-bc77-7de716298c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdef8ed0-db3e-4c8c-9b8f-c3cc750bf0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(\"output/part.parquet\")\n",
    "assert df.notna().all(axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab103ba7-491f-4375-958e-53be8ddcf657",
   "metadata": {},
   "outputs": [],
   "source": [
    "tim.stop()\n",
    "print(f\"Total time taken {str(tim.elapsed)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
