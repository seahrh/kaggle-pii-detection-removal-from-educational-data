{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c6bbbe74-776a-4fc5-9925-28fc95d1d20d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int16, min=-32768, max=32767\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import gc\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from typing import Dict, List, Set, Tuple, NamedTuple, Callable\n",
    "import scipy\n",
    "import scml\n",
    "from scml import pandasx as pdx\n",
    "tim = scml.Timer()\n",
    "tim.start()\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "percentiles=[.01, .05, .1, .2, .3, .4, .5, .6, .7, .8, .9, .95, .99]\n",
    "pd.set_option(\"max_info_columns\", 9999)\n",
    "pd.set_option(\"display.max_columns\", 9999)\n",
    "pd.set_option(\"display.max_rows\", 9999)\n",
    "pd.set_option('max_colwidth', 9999)\n",
    "tqdm.pandas()\n",
    "scml.seed_everything()\n",
    "info = np.iinfo(np.int16)\n",
    "print(f\"int16, min={info.min}, max={info.max}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1cb7a00f-1639-4055-8d6f-64da079d32dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DebertaV2TokenizerFast(name_or_path='huggingface/microsoft/deberta-v3-base', vocab_size=128000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '[CLS]', 'eos_token': '[SEP]', 'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
      "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t1: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t2: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t3: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
      "\t128000: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n",
      "model_input_names=['input_ids', 'token_type_ids', 'attention_mask']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ruhong/github/seahrh/kaggle-pii-detection-removal-from-educational-data/venv/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:515: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"huggingface/microsoft/deberta-v3-base\", is_fast=True)\n",
    "print(f\"{repr(tokenizer)}\\nmodel_input_names={tokenizer.model_input_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c083abd6-97f5-4973-8749-9123eea94b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'document': 7, 'full_text': \"Design Thinking for innovation reflexion-Avril 2021-Nathalie Sylla\\n\\nChallenge & selection\\n\\nThe tool I use to help all stakeholders finding their way through the complexity of a project is the  mind map.\\n\\nWhat exactly is a mind map? According to the definition of Buzan T. and Buzan B. (1999, Dessine-moi  l'intelligence. Paris: Les Éditions d'Organisation.), the mind map (or heuristic diagram) is a graphic  representation technique that follows the natural functioning of the mind and allows the brain's  potential to be released. Cf Annex1\\n\\nThis tool has many advantages:\\n\\n•  It is accessible to all and does not require significant material investment and can be done  quickly\\n\\n•  It is scalable\\n\\n•  It allows categorization and linking of information\\n\\n•  It can be applied to any type of situation: notetaking, problem solving, analysis, creation of  new ideas\\n\\n•  It is suitable for all people and is easy to learn\\n\\n•  It is fun and encourages exchanges\\n\\n•  It makes visible the dimension of projects, opportunities, interconnections\\n\\n•  It synthesizes\\n\\n•  It makes the project understandable\\n\\n•  It allows you to explore ideas\\n\\nThe creation of a mind map starts with an idea/problem located at its center. This starting point  generates ideas/work areas, incremented around this center in a radial structure, which in turn is  completed with as many branches as new ideas.\\n\\nThis tool enables creativity and logic to be mobilized, it is a map of the thoughts.\\n\\nCreativity is enhanced because participants feel comfortable with the method.\\n\\nApplication & Insight\\n\\nI start the process of the mind map creation with the stakeholders standing around a large board  (white or paper board). In the center of the board, I write and highlight the topic to design.\\n\\nThrough a series of questions, I guide the stakeholders in modelling the mind map. I adapt the series  of questions according to the topic to be addressed. In the type of questions, we can use: who, what,  when, where, why, how, how much.\\n\\nThe use of the “why” is very interesting to understand the origin. By this way, the interviewed person  frees itself from paradigms and thus dares to propose new ideas / ways of functioning. I plan two  hours for a workshop.\\n\\nDesign Thinking for innovation reflexion-Avril 2021-Nathalie Sylla\\n\\nAfter modelling the mind map on paper, I propose to the participants a digital visualization of their  work with the addition of color codes, images and interconnections. This second workshop also lasts  two hours and allows the mind map to evolve. Once familiarized with it, the stakeholders discover  the power of the tool. Then, the second workshop brings out even more ideas and constructive  exchanges between the stakeholders. Around this new mind map, they have learned to work  together and want to make visible the untold ideas.\\n\\nI now present all the projects I manage in this type of format in order to ease rapid understanding for  decision-makers. These presentations are the core of my business models. The decision-makers are  thus able to identify the opportunities of the projects and can take quick decisions to validate them.  They find answers to their questions thank to a schematic representation.\\n\\nApproach\\n\\nWhat I find amazing with the facilitation of this type of workshop is the participants commitment for  the project. This tool helps to give meaning. The participants appropriate the story and want to keep  writing it. Then, they easily become actors or sponsors of the project. A trust relationship is built,  thus facilitating the implementation of related actions.\\n\\nDesign Thinking for innovation reflexion-Avril 2021-Nathalie Sylla\\n\\nAnnex 1: Mind Map Shared facilities project\\n\\n\", 'tokens': ['Design', 'Thinking', 'for', 'innovation', 'reflexion', '-', 'Avril', '2021', '-', 'Nathalie', 'Sylla', '\\n\\n', 'Challenge', '&', 'selection', '\\n\\n', 'The', 'tool', 'I', 'use', 'to', 'help', 'all', 'stakeholders', 'finding', 'their', 'way', 'through', 'the', 'complexity', 'of', 'a', 'project', 'is', 'the', ' ', 'mind', 'map', '.', '\\n\\n', 'What', 'exactly', 'is', 'a', 'mind', 'map', '?', 'According', 'to', 'the', 'definition', 'of', 'Buzan', 'T.', 'and', 'Buzan', 'B.', '(', '1999', ',', 'Dessine', '-', 'moi', ' ', \"l'intelligence\", '.', 'Paris', ':', 'Les', 'Éditions', \"d'Organisation\", '.', ')', ',', 'the', 'mind', 'map', '(', 'or', 'heuristic', 'diagram', ')', 'is', 'a', 'graphic', ' ', 'representation', 'technique', 'that', 'follows', 'the', 'natural', 'functioning', 'of', 'the', 'mind', 'and', 'allows', 'the', 'brain', \"'s\", ' ', 'potential', 'to', 'be', 'released', '.', 'Cf', 'Annex1', '\\n\\n', 'This', 'tool', 'has', 'many', 'advantages', ':', '\\n\\n', '•', ' ', 'It', 'is', 'accessible', 'to', 'all', 'and', 'does', 'not', 'require', 'significant', 'material', 'investment', 'and', 'can', 'be', 'done', ' ', 'quickly', '\\n\\n', '•', ' ', 'It', 'is', 'scalable', '\\n\\n', '•', ' ', 'It', 'allows', 'categorization', 'and', 'linking', 'of', 'information', '\\n\\n', '•', ' ', 'It', 'can', 'be', 'applied', 'to', 'any', 'type', 'of', 'situation', ':', 'notetaking', ',', 'problem', 'solving', ',', 'analysis', ',', 'creation', 'of', ' ', 'new', 'ideas', '\\n\\n', '•', ' ', 'It', 'is', 'suitable', 'for', 'all', 'people', 'and', 'is', 'easy', 'to', 'learn', '\\n\\n', '•', ' ', 'It', 'is', 'fun', 'and', 'encourages', 'exchanges', '\\n\\n', '•', ' ', 'It', 'makes', 'visible', 'the', 'dimension', 'of', 'projects', ',', 'opportunities', ',', 'interconnections', '\\n\\n', '•', ' ', 'It', 'synthesizes', '\\n\\n', '•', ' ', 'It', 'makes', 'the', 'project', 'understandable', '\\n\\n', '•', ' ', 'It', 'allows', 'you', 'to', 'explore', 'ideas', '\\n\\n', 'The', 'creation', 'of', 'a', 'mind', 'map', 'starts', 'with', 'an', 'idea', '/', 'problem', 'located', 'at', 'its', 'center', '.', 'This', 'starting', 'point', ' ', 'generates', 'ideas', '/', 'work', 'areas', ',', 'incremented', 'around', 'this', 'center', 'in', 'a', 'radial', 'structure', ',', 'which', 'in', 'turn', 'is', ' ', 'completed', 'with', 'as', 'many', 'branches', 'as', 'new', 'ideas', '.', '\\n\\n', 'This', 'tool', 'enables', 'creativity', 'and', 'logic', 'to', 'be', 'mobilized', ',', 'it', 'is', 'a', 'map', 'of', 'the', 'thoughts', '.', '\\n\\n', 'Creativity', 'is', 'enhanced', 'because', 'participants', 'feel', 'comfortable', 'with', 'the', 'method', '.', '\\n\\n', 'Application', '&', 'Insight', '\\n\\n', 'I', 'start', 'the', 'process', 'of', 'the', 'mind', 'map', 'creation', 'with', 'the', 'stakeholders', 'standing', 'around', 'a', 'large', 'board', ' ', '(', 'white', 'or', 'paper', 'board', ')', '.', 'In', 'the', 'center', 'of', 'the', 'board', ',', 'I', 'write', 'and', 'highlight', 'the', 'topic', 'to', 'design', '.', '\\n\\n', 'Through', 'a', 'series', 'of', 'questions', ',', 'I', 'guide', 'the', 'stakeholders', 'in', 'modelling', 'the', 'mind', 'map', '.', 'I', 'adapt', 'the', 'series', ' ', 'of', 'questions', 'according', 'to', 'the', 'topic', 'to', 'be', 'addressed', '.', 'In', 'the', 'type', 'of', 'questions', ',', 'we', 'can', 'use', ':', 'who', ',', 'what', ',', ' ', 'when', ',', 'where', ',', 'why', ',', 'how', ',', 'how', 'much', '.', '\\n\\n', 'The', 'use', 'of', 'the', '“', 'why', '”', 'is', 'very', 'interesting', 'to', 'understand', 'the', 'origin', '.', 'By', 'this', 'way', ',', 'the', 'interviewed', 'person', ' ', 'frees', 'itself', 'from', 'paradigms', 'and', 'thus', 'dares', 'to', 'propose', 'new', 'ideas', '/', 'ways', 'of', 'functioning', '.', 'I', 'plan', 'two', ' ', 'hours', 'for', 'a', 'workshop', '.', '\\n\\n', 'Design', 'Thinking', 'for', 'innovation', 'reflexion', '-', 'Avril', '2021', '-', 'Nathalie', 'Sylla', '\\n\\n', 'After', 'modelling', 'the', 'mind', 'map', 'on', 'paper', ',', 'I', 'propose', 'to', 'the', 'participants', 'a', 'digital', 'visualization', 'of', 'their', ' ', 'work', 'with', 'the', 'addition', 'of', 'color', 'codes', ',', 'images', 'and', 'interconnections', '.', 'This', 'second', 'workshop', 'also', 'lasts', ' ', 'two', 'hours', 'and', 'allows', 'the', 'mind', 'map', 'to', 'evolve', '.', 'Once', 'familiarized', 'with', 'it', ',', 'the', 'stakeholders', 'discover', ' ', 'the', 'power', 'of', 'the', 'tool', '.', 'Then', ',', 'the', 'second', 'workshop', 'brings', 'out', 'even', 'more', 'ideas', 'and', 'constructive', ' ', 'exchanges', 'between', 'the', 'stakeholders', '.', 'Around', 'this', 'new', 'mind', 'map', ',', 'they', 'have', 'learned', 'to', 'work', ' ', 'together', 'and', 'want', 'to', 'make', 'visible', 'the', 'untold', 'ideas', '.', '\\n\\n', 'I', 'now', 'present', 'all', 'the', 'projects', 'I', 'manage', 'in', 'this', 'type', 'of', 'format', 'in', 'order', 'to', 'ease', 'rapid', 'understanding', 'for', ' ', 'decision', '-', 'makers', '.', 'These', 'presentations', 'are', 'the', 'core', 'of', 'my', 'business', 'models', '.', 'The', 'decision', '-', 'makers', 'are', ' ', 'thus', 'able', 'to', 'identify', 'the', 'opportunities', 'of', 'the', 'projects', 'and', 'can', 'take', 'quick', 'decisions', 'to', 'validate', 'them', '.', ' ', 'They', 'find', 'answers', 'to', 'their', 'questions', 'thank', 'to', 'a', 'schematic', 'representation', '.', '\\n\\n', 'Approach', '\\n\\n', 'What', 'I', 'find', 'amazing', 'with', 'the', 'facilitation', 'of', 'this', 'type', 'of', 'workshop', 'is', 'the', 'participants', 'commitment', 'for', ' ', 'the', 'project', '.', 'This', 'tool', 'helps', 'to', 'give', 'meaning', '.', 'The', 'participants', 'appropriate', 'the', 'story', 'and', 'want', 'to', 'keep', ' ', 'writing', 'it', '.', 'Then', ',', 'they', 'easily', 'become', 'actors', 'or', 'sponsors', 'of', 'the', 'project', '.', 'A', 'trust', 'relationship', 'is', 'built', ',', ' ', 'thus', 'facilitating', 'the', 'implementation', 'of', 'related', 'actions', '.', '\\n\\n', 'Design', 'Thinking', 'for', 'innovation', 'reflexion', '-', 'Avril', '2021', '-', 'Nathalie', 'Sylla', '\\n\\n', 'Annex', '1', ':', 'Mind', 'Map', 'Shared', 'facilities', 'project', '\\n\\n'], 'trailing_whitespace': [True, True, True, True, False, False, True, False, False, True, False, False, True, True, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, True, False, False, False, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, True, False, False, True, False, False, True, False, False, True, False, True, True, True, False, False, False, True, True, True, True, False, True, True, False, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, False, True, False, True, True, True, False, True, True, False, False, True, True, True, True, False, False, False, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, True, False, True, True, False, False, True, False, True, True, True, True, True, True, False, False, True, False, True, True, True, True, True, True, True, True, False, True, False, True, True, False, True, False, True, True, True, False, True, False, False, True, False, True, True, True, True, True, True, True, True, True, True, False, False, True, False, True, True, True, True, True, False, False, True, False, True, True, True, True, True, True, False, True, False, True, False, False, True, False, True, False, False, True, False, True, True, True, True, False, False, True, False, True, True, True, True, True, False, False, True, True, True, True, True, True, True, True, True, False, False, True, True, True, True, False, True, True, True, True, False, True, False, False, True, False, True, True, True, True, True, True, True, True, False, True, True, True, True, True, False, True, True, True, True, True, True, True, False, False, False, True, True, True, True, True, True, True, True, False, True, True, True, True, True, True, True, False, False, False, True, True, True, True, True, True, True, True, True, False, False, False, True, True, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, True, True, True, False, False, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, False, False, False, True, True, True, True, False, True, True, True, True, True, True, True, True, True, False, True, True, True, True, True, False, True, True, True, True, True, True, True, True, False, True, True, True, True, True, False, True, True, True, False, True, False, True, False, True, False, False, True, False, True, False, True, False, True, True, False, False, False, True, True, True, True, False, False, True, True, True, True, True, True, True, False, True, True, True, False, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, True, True, True, True, False, True, True, True, False, False, False, True, True, True, True, False, False, True, False, False, True, False, False, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, True, False, True, True, True, True, True, True, False, True, True, True, False, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, False, True, True, True, True, False, True, True, True, True, False, True, True, True, True, False, True, False, True, True, True, True, True, True, True, True, True, True, True, False, True, True, True, False, True, True, True, True, True, False, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, True, True, True, True, True, True, True, True, True, False, True, True, False, False, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, True, False, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, True, False, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, False, True, False, True, False, True, True, True, True, True, True, True, True, True, False, True, True, True, True, True, False, True, False, True, True, True, True, True, True, False, False, False, True, True, True, True, False, False, True, False, False, True, False, False, True, False, True, True, True, True, True, False, False], 'labels': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NAME_STUDENT', 'I-NAME_STUDENT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NAME_STUDENT', 'I-NAME_STUDENT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NAME_STUDENT', 'I-NAME_STUDENT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']}\n"
     ]
    }
   ],
   "source": [
    "with open(\"input/train.json\") as f:\n",
    "    data = json.load(f)\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b74c5e93-10aa-4aee-975a-7f349451cbee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6807/6807 [00:00<00:00, 19389.19it/s]\n"
     ]
    }
   ],
   "source": [
    "texts = []\n",
    "label_examples = []\n",
    "for row in tqdm(data):\n",
    "    did = int(row[\"document\"])\n",
    "    tokens = row[\"tokens\"]\n",
    "    labels = row[\"labels\"]\n",
    "    assert len(tokens)==len(labels)\n",
    "    ts=[]\n",
    "    la=\"\"\n",
    "    for i in range(len(tokens)):\n",
    "        if labels[i]==\"O\":\n",
    "            if len(ts)!=0:\n",
    "                label_examples.append({\"tokens\": \" \".join(ts), \"label\": la, \"did\": did})\n",
    "                ts=[]\n",
    "                la=\"\"\n",
    "            continue\n",
    "        if len(ts)==0:\n",
    "            la=labels[i][2:]\n",
    "        ts.append(tokens[i])\n",
    "    # remember to save the last entity!\n",
    "    if len(ts)!=0:\n",
    "        label_examples.append({\"tokens\": \" \".join(ts), \"label\": la, \"did\": did})\n",
    "    texts.append(str(row[\"full_text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bbd08a65-89e1-4b5e-9406-654bc93b9cc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    6807.000000\n",
       "mean      690.068753\n",
       "std       293.549286\n",
       "min        65.000000\n",
       "1%        164.000000\n",
       "5%        285.000000\n",
       "10%       359.000000\n",
       "20%       453.000000\n",
       "30%       523.000000\n",
       "40%       592.000000\n",
       "50%       655.000000\n",
       "60%       720.000000\n",
       "70%       799.000000\n",
       "80%       901.000000\n",
       "90%      1051.400000\n",
       "95%      1214.000000\n",
       "99%      1590.700000\n",
       "max      3074.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tokenizer(texts, truncation=False, add_special_tokens=False)\n",
    "deberta_tokens = [len(tokens) for tokens in x[\"input_ids\"]]\n",
    "pd.Series(deberta_tokens).describe(percentiles=percentiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a0b0e941-f007-41a5-b4df-090e8abe1822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1603 entries, 0 to 1602\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   tokens  1603 non-null   object\n",
      " 1   label   1603 non-null   object\n",
      " 2   did     1603 non-null   int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 37.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame.from_records(label_examples)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "973b22f3-57da-4ab7-a6b9-c155e826e037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>label</th>\n",
       "      <th>did</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nathalie Sylla</td>\n",
       "      <td>NAME_STUDENT</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nathalie Sylla</td>\n",
       "      <td>NAME_STUDENT</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nathalie Sylla</td>\n",
       "      <td>NAME_STUDENT</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Diego Estrada</td>\n",
       "      <td>NAME_STUDENT</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Diego Estrada</td>\n",
       "      <td>NAME_STUDENT</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           tokens         label  did\n",
       "0  Nathalie Sylla  NAME_STUDENT    7\n",
       "1  Nathalie Sylla  NAME_STUDENT    7\n",
       "2  Nathalie Sylla  NAME_STUDENT    7\n",
       "3   Diego Estrada  NAME_STUDENT   10\n",
       "4   Diego Estrada  NAME_STUDENT   10"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "25428cd0-0950-4d9f-b4a3-1909be146a9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>percent</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NAME_STUDENT</th>\n",
       "      <td>1365</td>\n",
       "      <td>0.851528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>URL_PERSONAL</th>\n",
       "      <td>109</td>\n",
       "      <td>0.067998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_NUM</th>\n",
       "      <td>76</td>\n",
       "      <td>0.047411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EMAIL</th>\n",
       "      <td>39</td>\n",
       "      <td>0.024329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USERNAME</th>\n",
       "      <td>6</td>\n",
       "      <td>0.003743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PHONE_NUM</th>\n",
       "      <td>6</td>\n",
       "      <td>0.003743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STREET_ADDRESS</th>\n",
       "      <td>2</td>\n",
       "      <td>0.001248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                count   percent\n",
       "label                          \n",
       "NAME_STUDENT     1365  0.851528\n",
       "URL_PERSONAL      109  0.067998\n",
       "ID_NUM             76  0.047411\n",
       "EMAIL              39  0.024329\n",
       "USERNAME            6  0.003743\n",
       "PHONE_NUM           6  0.003743\n",
       "STREET_ADDRESS      2  0.001248"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdx.value_counts(df[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1498fb15-2a6e-4c1e-8d80-edbd5e599152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.34 ms, sys: 551 µs, total: 1.89 ms\n",
      "Wall time: 1.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df.to_csv(f\"output/label_examples.csv\", index=False)\n",
    "assert df.notna().all(axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9eb48aba-3ab1-4d79-837b-ae1e4e336251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken 0:00:06.832944\n"
     ]
    }
   ],
   "source": [
    "tim.stop()\n",
    "print(f\"Total time taken {str(tim.elapsed)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
