{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7482808b-c292-4843-9dae-951ff5560b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int16, min=-32768, max=32767\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import scml\n",
    "from scml import pandasx as pdx\n",
    "from mylib.ner import NerModel\n",
    "tim = scml.Timer()\n",
    "tim.start()\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "percentiles=[.01, .05, .1, .2, .3, .4, .5, .6, .7, .8, .9, .95, .99]\n",
    "pd.set_option(\"max_info_columns\", 9999)\n",
    "pd.set_option(\"display.max_columns\", 9999)\n",
    "pd.set_option(\"display.max_rows\", 9999)\n",
    "pd.set_option('max_colwidth', 9999)\n",
    "tqdm.pandas()\n",
    "scml.seed_everything()\n",
    "info = np.iinfo(np.int16)\n",
    "print(f\"int16, min={info.min}, max={info.max}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d76be417-30e7-48e2-ae52-5ccd7cd8c0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_path = Path(\"models/ner/deberta_v3_large/20240309_092749\")\n",
    "ckpt_path = dst_path / \"lightning_logs/version_8/checkpoints/epoch=2-step=22044-val_loss=0.00168.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8e31294-3378-4130-8198-e5214e193fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "pd.set_option(\"max_info_columns\", 9999)\n",
    "pd.set_option(\"display.max_columns\", 9999)\n",
    "pd.set_option(\"display.max_rows\", 9999)\n",
    "pd.set_option('max_colwidth', 9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44916b07-d32e-4fb0-a869-76bddd1f86bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device=0, NVIDIA GeForce RTX 4070 Ti SUPER\n",
      "Mem Allocated: 0.0 GB\n",
      "Mem Cached:    0.0 GB\n",
      "device=1, NVIDIA GeForce RTX 4070 Ti SUPER\n",
      "Mem Allocated: 4.9 GB\n",
      "Mem Cached:    4.9 GB\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"device={i}, {torch.cuda.get_device_name(i)}\")\n",
    "        print('Mem Allocated:', round(torch.cuda.memory_allocated(i)/1024**3,1), 'GB')\n",
    "        print('Mem Cached:   ', round(torch.cuda.memory_reserved(i)/1024**3,1), 'GB')\n",
    "else:\n",
    "    print(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "787be70c-d2e0-4d62-b27b-c12efb83e25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForTokenClassification were not initialized from the model checkpoint at /mnt/c/huggingface/microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.7 s, sys: 3.15 s, total: 30.8 s\n",
      "Wall time: 38.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#model = NerModel.load_from_checkpoint(ckpt_path)\n",
    "model = NerModel.load_from_checkpoint(\n",
    "    ckpt_path,\n",
    "    pretrained_dir=Path(\"/mnt/c/huggingface/microsoft/deberta-v3-large\"),\n",
    "    lr=0,\n",
    "    scheduler_conf=[],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25fb6425-7dd8-4442-b491-37a67661af5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.29 s, sys: 242 ms, total: 2.53 s\n",
      "Wall time: 7.76 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.model_to_save.save_pretrained(str(dst_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c363b3f8-51b7-42f8-a917-b654fe2a3d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken 0:00:46.602131\n"
     ]
    }
   ],
   "source": [
    "tim.stop()\n",
    "print(f\"Total time taken {str(tim.elapsed)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
